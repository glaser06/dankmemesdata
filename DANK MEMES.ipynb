{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collective ultimate dank meme generator using ngram analysis. Crowd mentality is often found in cases where anonymity and brief exposure reign free in communicative environments. Using twitch chat data we will analyze for patterns of high repetition phrases such as \"LUL\", \"Harambe\", and \"9/11 was an inside job\" as well as other emoticons such as \"Kappa\" and \"PogChamp\". We will call these words \"memes\" and use a statistic \"dankness\" to measure how virulent these words are. Using an N-gram model we will generate subsequent \"memes\" based off the dankness statistic to generate the most likely to be used dank meme.\n",
    "\n",
    "We use the twitch chat API to set up an IRC bot that sits in various channels that records the output of these channels. We decided to use these channels based off popularity; we intend to see a correlation between dankness and popularity of channel. These chat logs are massive in size since anonymity gives people leeway to post whatever they want whether it be offensive, politically charged, or pure nonsense. We note that in general, it is easier to convey a certain message with a shorter amount of words which can often lead to short non-sensical words that are generally accepted by the chat to have a certain meaning. We see that in the data, short phrases are favored over longer sentences. In fact, twitch has its own emoticons usually some sort of facial expression to indicate a message. One exception to the rule are \"copy-pastas\" which are long, pre-written paragraphs of text that are copy and pasted throughout chat, usually indicating satirical undertones although sometimes more direct. Chat will also react to things going on during the stream session. From this we can see clustering of chats being sent (which will be indicative from timestamps) around certain times usually of similar content.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to irc.twitch.tv on port 6667\n",
      "USER: tacobff\n",
      "OAUTH: oauth:******************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set up for methods and stuff\n",
    "\n",
    "import datetime\n",
    "import socket\n",
    "import select\n",
    "import re\n",
    "\n",
    "channels = [\n",
    "    'tsm_bjergsen',\n",
    "    'c9sneaky',\n",
    "    'trick2g',\n",
    "    'tsm_doublelift',\n",
    "    'nightblue3',\n",
    "    'imaqtpie',\n",
    "    'rush'\n",
    "    ]\n",
    "username = 'tacobff'\n",
    "oauth = 'oauth:f9gp83pucfzriac4hjsfh5hwjdqho6'\n",
    "\n",
    "channelfiles = {}\n",
    "\n",
    "for name in channels:\n",
    "    channelfiles[name] = open(name+'.txt', 'a+')\n",
    "#     channelfiles[name].write(\"\\n \\n------------ \\n \\n \\n \\n\")\n",
    "#     channelfiles[name].write(\"new session\\n\")\n",
    "#     channelfiles[name].write(\"\\n \\n \\n ------------ \\n \\n \\n\")\n",
    "\n",
    "def ping():\n",
    "    ''' Respond to the server 'pinging' (Stays connected) '''\n",
    "    socks[0].send('PONG :pingis\\n')\n",
    "    print('PONG: Client > tmi.twitch.tv')\n",
    "\n",
    "def sendmsg(chan,msg):\n",
    "    ''' Send specified message to the channel '''\n",
    "    socks[0].send('PRIVMSG '+chan+' :'+msg+'\\n')\n",
    "    print('[BOT] -> '+chan+': '+msg+'\\n')\n",
    "\n",
    "def sendwhis(user,msg):\n",
    "    socks[1].send('PRIVMSG #jtv :/w '+user+' '+msg+'\\n')\n",
    "    print('[BOT] -> '+user+': '+msg+'\\n')\n",
    "\n",
    "def getmsg(msg):\n",
    "    ''' GET IMPORTANT MESSAGE '''\n",
    "    if(re.findall('@(.*).tmi.twitch.tv PRIVMSG (.*) :(.*)',msg)):\n",
    "        msg_edit = msg.split(':',2)\n",
    "        if(len(msg_edit) > 2):\n",
    "            user = msg_edit[1].split('!',1)[0] # User\n",
    "            message = msg_edit[2] # Message\n",
    "            channel = re.findall('PRIVMSG (.*)',msg_edit[1]) # Channel\n",
    "            #print channel[0][1:-1]\n",
    "            privmsg = re.findall('@(.*).tmi.twitch.tv PRIVMSG (.*) :(.*)',msg)\n",
    "            ''' CONVERT TO ARRAY '''\n",
    "            privmsg = [x for xs in privmsg for x in xs]\n",
    "\n",
    "            datelog = datetime.datetime.now()\n",
    "\n",
    "            ''' PRINT TO CONSOLE '''\n",
    "            if(len(privmsg) > 0):\n",
    "                if len(channel) > 0:\n",
    "                    chan = channel[0] \n",
    "                    if len(chan) >= 3:\n",
    "    \n",
    "                        #print ('['+str(datelog.hour)+':'+str(datelog.minute)+':'+str(datelog.second)+'] '+user+' @ '+channel[0][:-1]+': '+message+'\\n')\n",
    "                        channelfiles[channel[0][1:-1]].write('['+str(datelog.day)+':'+str(datelog.hour)+':'+str(datelog.minute)+':'+str(datelog.second)+'] '+user+' @ '+channel[0][:-1]+': '+message+'\\n')\n",
    "                \n",
    "    if(re.findall('@(.*).tmi.twitch.tv WHISPER (.*) :(.*)',msg)):\n",
    "        whisper = re.findall('@(.*).tmi.twitch.tv WHISPER (.*) :(.*)',msg)\n",
    "        whisper = [x for xs in whisper for x in xs]\n",
    "\n",
    "        ''' PRINT TO CONSOLE '''\n",
    "        if(len(whisper) > 0):\n",
    "            ''' PRINT WHISPER TO CONSOLE '''\n",
    "            print('*WHISPER* '+whisper[0]+': '+whisper[2])\n",
    "            \n",
    "\n",
    "socks = [socket.socket(),socket.socket()]\n",
    "\n",
    "socks[0].connect(('irc.twitch.tv',6667))\n",
    "\n",
    "socks[0].send('PASS '+oauth+'\\n')\n",
    "socks[0].send('NICK '+username+'\\n')\n",
    "\n",
    "# socks[0].send(\"JOIN #tsm_bjergsen \\r\\n\")\n",
    "\n",
    "for val in channels:\n",
    "\n",
    "    socks[0].send('JOIN #'+val+'\\n')\n",
    "    \n",
    "print('Connected to irc.twitch.tv on port 6667')\n",
    "print('USER: '+username)\n",
    "print('OAUTH: oauth:'+'*'*30)\n",
    "print('\\n')\n",
    "\n",
    "temp = 0\n",
    "count = 0\n",
    "while True:\n",
    "  \n",
    "    (sread,swrite,sexc) = select.select(socks,socks,[],120)\n",
    "    for sock in sread:\n",
    "  \n",
    "        ''' Receive data from the server '''\n",
    "        msg = sock.recv(2048)\n",
    "        if(msg == ''):\n",
    "            temp + 1\n",
    "            if(temp > 5):\n",
    "                print('Connection might have been terminated')\n",
    "    \n",
    "        ''' Remove any linebreaks from the message '''\n",
    "        msg = msg.strip('\\n\\r')\n",
    "\n",
    "        ''' DISPLAY MESSAGE IN SHELL '''\n",
    "        getmsg(msg)\n",
    "#         print(msg)\n",
    "\n",
    "\n",
    "        # ANYTHING TO DO WITH CHAT FROM CHANNELS\n",
    "        ''' GET THE INFO FROM THE SERVER '''\n",
    "        check = re.findall('@(.*).tmi.twitch.tv PRIVMSG (.*) :(.*)',msg)\n",
    "        if(len(check) > 0):\n",
    "            msg_edit = msg.split(':',2)\n",
    "            if(len(msg_edit) > 2):\n",
    "                user = msg_edit[1].split('!',1)[0] # User\n",
    "                message = msg_edit[2] # Message\n",
    "                channel = msg_edit[1].split(' ',2)[2][:-1] # Channel\n",
    "\n",
    "                msg_split = str.split(message)\n",
    " \n",
    "                \n",
    "\n",
    "                        \n",
    "        # ANYTHING TO DO WITH WHISPERS RECIEVED FROM USERS\n",
    "        check = re.findall('@(.*).tmi.twitch.tv WHISPER (.*) :(.*)',msg)\n",
    "        if(len(check) > 0):\n",
    "            msg_edit = msg.split(':',2)\n",
    "            if(len(msg) > 2):\n",
    "                user = msg_edit[1].split('!',1)[0] # User\n",
    "                message = msg_edit[2] # Message\n",
    "                channel = msg_edit[1].split(' ',2)[2][:-1] # Channel\n",
    "\n",
    "                whis_split = str.split(message)\n",
    "                               \n",
    " \n",
    "\n",
    "        ''' Respond to server pings '''\n",
    "        if msg.find('PING :') != -1:\n",
    "            print('PING: tmi.twitch.tv > Client')\n",
    "            ping()\n",
    "print \"stopped\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How mindless is twitch chat?\n",
    "\n",
    "The average twitch user’s chat logs is made up of two kinds of messages: spam and the creation of messages for other users to spam. Because of the genuine lack of creativity and intelligence among the average twitch user’s chat logs, we hypothesize that a computer can emulate both kinds of messages. \n",
    "\n",
    "Emulating spam is trivial; often in twitch chat one message is spammed so often that it becomes difficult to see messages of any other kind. A computer would have no problem keeping track of the frequencies of messages so its an easy task for a computer.\n",
    "\n",
    "Original messages are much more difficult to create. First, in order to try and emulate creative messages, we will establish a measure called dankness. We believe that a successful original message will be spammed more than unsuccessful ones, so dankness will be defined as the number of times a phrase was chatted. Due to the seemingly randomness nature of Twitch chat, we first approach this problem using an ngram model run on the Twitch chat data. We tried using a trigram model at first, but we found that a interpolated model with bigram and unigrams works a lot better due to the small average length of each message. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "def tokenize_by_word(sentence):\n",
    "\treturn nltk.word_tokenize(sentence)\n",
    "class NgramModel:\n",
    "\t\"\"\"\n",
    "\t__init__ initializes a NgramModel. \n",
    "\n",
    "\tParameters:\n",
    "\tn                       the n used in the ngram model\n",
    "\ttrain                   a string containing a training text\n",
    "\tunknown_replace_limit   if a word in the training text appears less than this many times, replace it with 'UNKNOWNWORD'\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, n, train, unknown_replace_limit=0):\n",
    "\t\tif (n < 0):\n",
    "\t\t\traise Exception(\"N must be greater than or equal to zero to make an Ngram model.\")\n",
    "\n",
    "\t\ttokens = tokenize_by_word(train)\n",
    "\t\ttokens_count = dict()\n",
    "\t\tfor token in tokens:\n",
    "\t\t\tif token not in tokens_count:\n",
    "\t\t\t\ttokens_count[token] = 1\n",
    "\t\t\telse:\n",
    "\t\t\t\ttokens_count[token] += 1\n",
    "\n",
    "\t\ttokens = [\"UNKNOWNWORD\" if tokens_count[token] < unknown_replace_limit else token for token in tokens]\n",
    "\n",
    "\n",
    "\t\tngrams = zip(*[tokens[i:] for i in range(n)])\n",
    "\t\tngrams_count = dict()\n",
    "\t\tfor ngram in ngrams:\n",
    "\t\t\tif ngram not in ngrams_count:\n",
    "\t\t\t\tngrams_count[ngram] = 1\n",
    "\t\t\telse:\n",
    "\t\t\t\tngrams_count[ngram] += 1\n",
    "\n",
    "\t\tn1grams = []\n",
    "\t\tn1grams_count = dict()\n",
    "\t\tif (n > 1):\n",
    "\t\t\tn1grams = zip(*[tokens[i:] for i in range(n - 1)])\n",
    "\t\t\tfor n1gram in n1grams:\n",
    "\t\t\t\tif n1gram not in n1grams_count:\n",
    "\t\t\t\t\tn1grams_count[n1gram] = 1\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tn1grams_count[n1gram] += 1\n",
    "\n",
    "\t\tself.n = n\n",
    "\t\tself.ngrams_count = ngrams_count\n",
    "\t\tself.n1grams_count = n1grams_count\n",
    "\t\tself.vocab_size = len(set(tokens))\n",
    "\n",
    "\t\"\"\"\n",
    "\tperplexity: string -> float\n",
    "\n",
    "\tReturns the perplexity of 'text' according to this language model.\n",
    "\t\"\"\"\n",
    "\tdef perplexity(self, text):\n",
    "\t\ttokens = tokenizer.tokenize_by_word(text)\n",
    "\t\tif (len(tokens) < self.n):\n",
    "\t\t\t\traise Exception(\"text does not have enough words to calculate perplexity\")\n",
    "\t\ts = 0.0\n",
    "\t\tnum = 0\n",
    "\t\tif (self. n > 0):\n",
    "\t\t\tfor token in zip(*[tokens[i:] for i in range(self.n)]):\n",
    "\t\t\t\tprob = self.probability(token)\n",
    "\n",
    "\t\t\t\tif (prob == 0.0):\n",
    "\t\t\t\t\tprob = 0.00000000000000000000001\n",
    "\n",
    "\t\t\t\ts += math.log(prob)\n",
    "\t\t\t\tnum += 1\n",
    "\n",
    "\t\t\treturn math.exp(-s / num)\n",
    "\t\telse:\n",
    "\t\t\tfor token in tokens:\n",
    "\t\t\t\tprob = self.probability(token)\n",
    "\n",
    "\t\t\t\tif (prob == 0.0):\n",
    "\t\t\t\t\tprob = 0.00000000000000000000001\n",
    "\n",
    "\t\t\t\ts += math.log(prob)\n",
    "\t\t\t\tnum += 1\n",
    "\n",
    "\t\t\treturn math.exp(-s / num)\n",
    "\n",
    "\t'''\n",
    "\tprobability: tuple -> float\n",
    "\n",
    "\tprobability takes in a n-length tuple representing a ngram and returns its probability\n",
    "\taccording to this language model.\n",
    "\t'''\n",
    "\tdef probability(self, ngram):\n",
    "\t\tprob = 0.0\n",
    "\t\tif (self.n > 1):\n",
    "\t\t\tn1gram = tuple(list(ngram)[0:(self.n - 1)])\n",
    "\t\t\tif ngram in self.ngrams_count and n1gram in self.n1grams_count:\n",
    "\t\t\t\tprob = float(self.ngrams_count[ngram]) / float(self.n1grams_count[n1gram])\n",
    "\t\telif (self.n == 0):\n",
    "\t\t\tprob = float(1) / float(self.vocab_size)\n",
    "\t\telse:\n",
    "\t\t\t# This is for the unigram case\n",
    "\t\t\tif ngram in self.ngrams_count:\n",
    "\t\t\t\ttotal = 0\n",
    "\t\t\t\tfor key in self.ngrams_count:\n",
    "\t\t\t\t\ttotal += self.ngrams_count[key]\n",
    "\t\t\t\tprob = float(self.ngrams_count[ngram]) / float(total)\n",
    "\n",
    "\t\treturn prob\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "InterpolatedModel: a class for representing an interpolated ngram model\n",
    "'''\n",
    "class InterpolatedModel:\n",
    "\t\"\"\"\n",
    "\t__init__ initializes an InterpolatedModel. \n",
    "\n",
    "\tParameters:\n",
    "\tmodels      the models used in the interpolation\n",
    "\tlambdas     the coefficients for each model\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, models, lambdas):\n",
    "\t\tif (not len(models) == len(lambdas)):\n",
    "\t\t\traise Exception(\"The length of the models list must be the same as the length of the lambdas list\")\n",
    "\n",
    "\t\tif (not sum(lambdas) == 1.0):\n",
    "\t\t\traise Exception(\"The sum of the lambda coefficients must be 1\")\n",
    "\n",
    "\t\tself.lambdas = lambdas\n",
    "\t\tself.models = models\n",
    "\t\tself.n = max([model.n for model in models])\n",
    "\n",
    "\n",
    "\t'''\n",
    "\tprobability: tuple -> float\n",
    "\n",
    "\tprobability takes in a tuple representing a ngram and returns its probability\n",
    "\taccording to this language model. The tuple length must be less than or equal to n for\n",
    "\tthe largest model.\n",
    "\t'''\n",
    "\tdef probability(self, ngram):\n",
    "\t\tprob = 0.0\n",
    "\t\tfor coefficient, model in zip(self.lambdas, self.models):\n",
    "\t\t \tn = model.n\n",
    "\t\t \tif (len(ngram) >= n):\t\n",
    "\t\t\t \tword = tuple(list(ngram)[-n:])\n",
    "\t\t\t \tprob += coefficient * model.probability(word)\n",
    "\t\treturn prob\n",
    "\n",
    "\t\"\"\"\n",
    "\tperplexity: string -> float\n",
    "\n",
    "\tReturns the perplexity of 'text' according to this language model.\n",
    "\t\"\"\"\n",
    "\tdef perplexity(self, text):\n",
    "\t\ttokens = tokenizer.tokenize_by_word(text)\n",
    "\t\ts = 0.0\n",
    "\t\tnum = 0\n",
    "\t\tfor i in range(0, len(tokens)):\n",
    "\t\t\tif (i < self.n):\n",
    "\t\t\t\tprob = self.probability(tuple(tokens[0:i + 1]))\n",
    "\t\t\telse:\n",
    "\t\t\t\tprob = self.probability(tuple(tokens[i - self.n + 1:i + 1]))\n",
    "\n",
    "\t\t\tif (prob == 0.0):\n",
    "\t\t\t\tprob = 0.00000000000000000000001\n",
    "\t\t\ts += math.log(prob)\n",
    "\t\t\tnum += 1\n",
    "\t\treturn math.exp(-s / num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of now, we have gathered a lot of chat data from multiple different streamers and stored them separately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
